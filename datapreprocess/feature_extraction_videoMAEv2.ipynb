{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from datetime import datetime\n",
    "\n",
    "import models\n",
    "from timm.models import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"VS_03.이상행동_14.교통약자\"\n",
    "\n",
    "root = \"/data/ephemeral/home/datasets/abnormal/val/\" + folder_name +\"/\"\n",
    "\n",
    "npy_root = \"./npy/\"\n",
    "\n",
    "if not os.path.exists(npy_root):\n",
    "    os.makedirs(npy_root)\n",
    "# if not os.path.exists(npy_root+folder_name):\n",
    "#     os.makedirs(npy_root+folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>> file_list: ['C_3_14_69_BU_DYA_07-20_14-59-57_e_DF6_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CC_DF2_M4.mp4', 'C_3_14_72_BU_DYA_07-20_15-07-07_a_DF6_M4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CA_DF2_F4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CB_DF2_M4.mp4', 'C_3_14_71_BU_DYA_07-20_15-04-31_c_DF6_M4.mp4', 'C_3_14_65_BU_DYA_07-19_12-30-50_d_DF6_F4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CA_DF2_M4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_c_DF6_F4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CE_DF2_M4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_e_DF6_F4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CD_DF2_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_f_DF6_F4.mp4', 'C_3_14_71_BU_DYA_07-20_15-04-31_a_DF6_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_c_DF6_M4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CF_DF2_M4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CE_DF2_F4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_d_DF6_M4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CB_DF2_F4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CA_DF2_M4.mp4', 'C_3_14_65_BU_DYA_07-19_12-30-50_f_DF6_F4.mp4', 'C_3_14_71_BU_DYA_07-20_15-04-31_b_DF6_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CB_DF2_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CF_DF2_M4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CF_DF2_M4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CD_DF2_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CD_DF2_M4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CE_DF2_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CB_DF2_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CD_DF2_M4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_a_DF6_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_f_DF6_F4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CC_DF2_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CF_DF2_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CC_DF2_M4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_c_DF6_F4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_f_DF6_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CA_DF2_M4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CD_DF2_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CD_DF2_M4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_a_DF6_F4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CC_DF2_M4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_e_DF6_F4.mp4', 'C_3_14_72_BU_DYA_07-20_15-07-07_c_DF6_M4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_f_DF6_F4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CC_DF2_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CE_DF2_M4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_d_DF6_F4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_f_DF6_M4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_c_DF6_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_e_DF6_M4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CB_DF2_F4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CA_DF2_M4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_b_DF6_M4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_b_DF6_F4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CE_DF2_M4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CC_DF2_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_c_DF6_F4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_d_DF6_F4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CB_DF2_M4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CA_DF2_F4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CA_DF2_M4.mp4', 'C_3_14_72_BU_DYA_07-20_15-07-07_b_DF6_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CE_DF2_M4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_e_DF6_F4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CB_DF2_M4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CF_DF2_F4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_b_DF6_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_d_DF6_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_b_DF6_F4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_d_DF6_M4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CD_DF2_F4.mp4', 'C_3_14_65_BU_DYA_07-19_12-30-50_e_DF6_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_a_DF6_F4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CF_DF2_F4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CF_DF2_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_a_DF6_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_b_DF6_M4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CC_DF2_F4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_a_DF6_M4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CE_DF2_F4.mp4']\n",
      "==>> file_list: ['C_3_14_65_BU_DYA_07-19_12-30-50_d_DF6_F4.mp4', 'C_3_14_65_BU_DYA_07-19_12-30-50_e_DF6_F4.mp4', 'C_3_14_65_BU_DYA_07-19_12-30-50_f_DF6_F4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CA_DF2_F4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CB_DF2_F4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CC_DF2_F4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CD_DF2_F4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CE_DF2_F4.mp4', 'C_3_14_65_BU_DYB_10-13_12-03-56_CF_DF2_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_a_DF6_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_b_DF6_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_c_DF6_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_d_DF6_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_e_DF6_F4.mp4', 'C_3_14_66_BU_DYA_07-19_11-46-00_f_DF6_F4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CA_DF2_F4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CB_DF2_F4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CC_DF2_F4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CD_DF2_F4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CE_DF2_F4.mp4', 'C_3_14_66_BU_DYB_10-13_12-06-02_CF_DF2_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_a_DF6_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_b_DF6_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_c_DF6_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_d_DF6_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_e_DF6_F4.mp4', 'C_3_14_67_BU_DYA_07-19_11-54-57_f_DF6_F4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CA_DF2_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CB_DF2_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CC_DF2_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CD_DF2_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CE_DF2_M4.mp4', 'C_3_14_67_BU_DYB_10-13_10-14-49_CF_DF2_M4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_a_DF6_F4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_b_DF6_F4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_c_DF6_F4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_d_DF6_F4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_e_DF6_F4.mp4', 'C_3_14_68_BU_DYA_07-19_12-04-44_f_DF6_F4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CA_DF2_M4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CB_DF2_M4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CC_DF2_M4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CD_DF2_M4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CE_DF2_M4.mp4', 'C_3_14_68_BU_DYB_10-13_10-17-17_CF_DF2_M4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_a_DF6_M4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_b_DF6_M4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_c_DF6_M4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_d_DF6_M4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_e_DF6_M4.mp4', 'C_3_14_69_BU_DYA_07-20_14-59-57_f_DF6_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CA_DF2_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CB_DF2_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CC_DF2_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CD_DF2_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CE_DF2_M4.mp4', 'C_3_14_69_BU_DYB_10-13_10-19-42_CF_DF2_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_a_DF6_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_b_DF6_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_c_DF6_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_d_DF6_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_e_DF6_M4.mp4', 'C_3_14_70_BU_DYA_07-20_15-01-52_f_DF6_M4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CA_DF2_M4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CB_DF2_M4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CC_DF2_M4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CD_DF2_M4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CE_DF2_M4.mp4', 'C_3_14_70_BU_DYB_10-13_10-21-44_CF_DF2_M4.mp4', 'C_3_14_71_BU_DYA_07-20_15-04-31_a_DF6_M4.mp4', 'C_3_14_71_BU_DYA_07-20_15-04-31_b_DF6_M4.mp4', 'C_3_14_71_BU_DYA_07-20_15-04-31_c_DF6_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CA_DF2_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CB_DF2_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CC_DF2_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CD_DF2_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CE_DF2_M4.mp4', 'C_3_14_71_BU_DYB_10-13_10-45-53_CF_DF2_M4.mp4', 'C_3_14_72_BU_DYA_07-20_15-07-07_a_DF6_M4.mp4', 'C_3_14_72_BU_DYA_07-20_15-07-07_b_DF6_M4.mp4', 'C_3_14_72_BU_DYA_07-20_15-07-07_c_DF6_M4.mp4']\n"
     ]
    }
   ],
   "source": [
    "file_list = os.listdir(root)\n",
    "print(f\"==>> file_list: {file_list}\")\n",
    "file_list.sort()\n",
    "print(f\"==>> file_list: {file_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# segments_num = 1\n",
    "# # 모델에 들어갈 frame수는 16 * segments_num\n",
    "\n",
    "# model = create_model(\n",
    "#     \"vit_small_patch16_224\",\n",
    "#     # \"vit_base_patch16_224\",\n",
    "#     img_size=224,\n",
    "#     pretrained=False,\n",
    "#     num_classes=710,\n",
    "#     all_frames=16 * segments_num,\n",
    "#     # tubelet_size=args.tubelet_size,\n",
    "#     # drop_rate=args.drop,\n",
    "#     # drop_path_rate=args.drop_path,\n",
    "#     # attn_drop_rate=args.attn_drop_rate,\n",
    "#     # head_drop_rate=args.head_drop_rate,\n",
    "#     # drop_block_rate=None,\n",
    "#     # use_mean_pooling=args.use_mean_pooling,\n",
    "#     # init_scale=args.init_scale,\n",
    "#     # with_cp=args.with_checkpoint,\n",
    "# )\n",
    "\n",
    "# load_dict = torch.load(\n",
    "#     \"/data/ephemeral/home/level2-3-cv-finalproject-cv-06/datapreprocess/vit_s_k710_dl_from_giant.pth\"\n",
    "# )\n",
    "# # load_dict = torch.load(\n",
    "# #     \"/data/ephemeral/home/level2-3-cv-finalproject-cv-06/datapreprocess/vit_b_k710_dl_from_giant.pth\"\n",
    "# # )\n",
    "# # backbone pth 경로\n",
    "\n",
    "# model.load_state_dict(load_dict[\"module\"])\n",
    "\n",
    "# model.to(\"cuda\")\n",
    "# model.eval()\n",
    "\n",
    "# tf = A.Resize(224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# file_list = file_list[4:6]\n",
    "# print(f\"==>> file_list: {file_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "\n",
    "# # Loop through the video frames\n",
    "# for file_name in file_list:\n",
    "#     path = root + file_name\n",
    "\n",
    "#     time_start = datetime.now()\n",
    "\n",
    "#     print(f\"{file_name} feature extracting starts\")\n",
    "\n",
    "#     cap = cv2.VideoCapture(path)\n",
    "\n",
    "#     # 710차원 feature array 저장할 list\n",
    "#     np_list = []\n",
    "\n",
    "#     # 16 * segments_num 프레임씩 저장할 list\n",
    "#     frames = []\n",
    "#     frame_count = 0\n",
    "\n",
    "#     # input tensor 저장할 list\n",
    "#     input_list = []\n",
    "#     input_count = 0\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         # Read a frame from the video\n",
    "#         success, frame = cap.read()\n",
    "#         # frame.shape = (height, width, 3)\n",
    "\n",
    "#         frame_count += 1  # Increment frame count\n",
    "\n",
    "#         if success:\n",
    "#             frame = tf(image=frame)[\"image\"]\n",
    "#             # frame.shape = (224, 224, 3)\n",
    "\n",
    "#             frame = np.expand_dims(frame, axis=0)\n",
    "#             # frame.shape = (1, 224, 224, 3)\n",
    "#             frames.append(frame.copy())\n",
    "\n",
    "#             if frame_count == 16 * segments_num:\n",
    "#                 assert len(frames) == 16 * segments_num\n",
    "#                 frames = np.concatenate(frames)\n",
    "#                 # in_frames.shape = (16 * segments_num, 224, 224, 3)\n",
    "#                 in_frames = frames.transpose(3, 0, 1, 2)\n",
    "#                 # # in_frames.shape = (RGB 3, frame T=16 * segments_num, H=224, W=224)\n",
    "#                 in_frames = np.expand_dims(in_frames, axis=0)\n",
    "#                 # in_frames.shape = (1, 3, 16 * segments_num, 224, 224)\n",
    "#                 in_frames = torch.from_numpy(in_frames).float()\n",
    "#                 # in_frames.shape == torch.Size([1, 3, 16 * segments_num, 224, 224])\n",
    "\n",
    "#                 input_list.append(in_frames.detach().clone())\n",
    "\n",
    "#                 frame_count = 0\n",
    "#                 frames = []\n",
    "\n",
    "#                 input_count += 1\n",
    "\n",
    "#                 if input_count == batch_size:\n",
    "#                     # input_batch.shape == torch.Size([batch_size, 3, 16 * segments_num, 224, 224])\n",
    "#                     input_batch = torch.cat(input_list, dim=0).to(\"cuda\")\n",
    "\n",
    "#                     with torch.no_grad():\n",
    "#                         output = model(input_batch)\n",
    "#                         # output.shape == torch.Size([batch_size, 710])\n",
    "\n",
    "#                     np_list.append(output.cpu().numpy())\n",
    "\n",
    "#                     input_count = 0\n",
    "#                     input_list = []\n",
    "#         else:\n",
    "#             # 남은 프레임, input_list가 지정 개수에서 모자를 때 예외 처리\n",
    "#             if frame_count != 0:\n",
    "#                 len_frames_left = 16 * segments_num - len(frames)\n",
    "#                 # len_input_list_left = batch_size - len(input_list)\n",
    "#                 for i in range(len_frames_left):\n",
    "#                     frames.append(frames[-1].copy())\n",
    "\n",
    "#                 assert len(frames) == 16 * segments_num\n",
    "\n",
    "#                 frames = np.concatenate(frames)\n",
    "#                 # in_frames.shape = (16 * segments_num, 224, 224, 3)\n",
    "#                 in_frames = frames.transpose(3, 0, 1, 2)\n",
    "#                 # # in_frames.shape = (RGB 3, frame T=16 * segments_num, H=224, W=224)\n",
    "#                 in_frames = np.expand_dims(in_frames, axis=0)\n",
    "#                 # in_frames.shape = (1, 3, 16 * segments_num, 224, 224)\n",
    "#                 in_frames = torch.from_numpy(in_frames).float()\n",
    "#                 # in_frames.shape == torch.Size([1, 3, 16 * segments_num, 224, 224])\n",
    "\n",
    "#                 input_list.append(in_frames.detach().clone())\n",
    "\n",
    "#                 # assert len(input_list) == batch_size\n",
    "\n",
    "#                 # input_batch.shape == torch.Size([batch_size, 3, 16 * segments_num, 224, 224])\n",
    "#                 input_batch = torch.cat(input_list, dim=0).to(\"cuda\")\n",
    "\n",
    "#                 with torch.no_grad():\n",
    "#                     output = model(input_batch)\n",
    "#                     # output.shape == torch.Size([len(input_list), 710])\n",
    "\n",
    "#                 np_list.append(output.cpu().numpy())\n",
    "\n",
    "#                 frame_count = 0\n",
    "#                 frames = []\n",
    "#                 input_count = 0\n",
    "#                 input_list = []\n",
    "\n",
    "#             # Break the loop if the end of the video is reached\n",
    "#             break\n",
    "\n",
    "#     file_outputs = np.concatenate(np_list)\n",
    "#     print(f\"==>> file_outputs.shape: {file_outputs.shape}\")\n",
    "\n",
    "#     np.save((npy_root + folder_name + \"/\" + file_name), file_outputs)\n",
    "\n",
    "#     cap.release()\n",
    "\n",
    "#     time_end = datetime.now()\n",
    "#     total_time = time_end - time_start\n",
    "#     total_time = str(total_time).split(\".\")[0]\n",
    "\n",
    "#     print(f\"{file_name} feature extracting ended. Elapsed time: {total_time}\")\n",
    "\n",
    "# # cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(npy_root + folder_name +\"_base\"):\n",
    "    os.makedirs(npy_root + folder_name + \"_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m segments_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 모델에 들어갈 frame수는 16 * segments_num\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# \"vit_small_patch16_224\",\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvit_base_patch16_224\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m710\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mall_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msegments_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# tubelet_size=args.tubelet_size,\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# drop_rate=args.drop,\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# drop_path_rate=args.drop_path,\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# attn_drop_rate=args.attn_drop_rate,\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# head_drop_rate=args.head_drop_rate,\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# drop_block_rate=None,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# use_mean_pooling=args.use_mean_pooling,\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# init_scale=args.init_scale,\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# with_cp=args.with_checkpoint,\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# load_dict = torch.load(\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     \"/data/ephemeral/home/level2-3-cv-finalproject-cv-06/datapreprocess/vit_s_k710_dl_from_giant.pth\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     25\u001b[0m load_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/ephemeral/home/level2-3-cv-finalproject-cv-06/datapreprocess/vit_b_k710_dl_from_giant.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m )\n",
      "File \u001b[0;32m~/level2-3-cv-finalproject-cv-06/.venv/lib/python3.11/site-packages/timm/models/factory.py:81\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnknown model (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m model_name)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable\u001b[38;5;241m=\u001b[39mscriptable, exportable\u001b[38;5;241m=\u001b[39mexportable, no_jit\u001b[38;5;241m=\u001b[39mno_jit):\n\u001b[0;32m---> 81\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m     84\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/level2-3-cv-finalproject-cv-06/datapreprocess/models/modeling_finetune.py:474\u001b[0m, in \u001b[0;36mvit_base_patch16_224\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;129m@register_model\u001b[39m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvit_base_patch16_224\u001b[39m(pretrained\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 474\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mVisionTransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m768\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m12\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmlp_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqkv_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m     model\u001b[38;5;241m.\u001b[39mdefault_cfg \u001b[38;5;241m=\u001b[39m _cfg()\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/level2-3-cv-finalproject-cv-06/datapreprocess/models/modeling_finetune.py:369\u001b[0m, in \u001b[0;36mVisionTransformer.__init__\u001b[0;34m(self, img_size, patch_size, in_chans, num_classes, embed_dim, depth, num_heads, mlp_ratio, qkv_bias, qk_scale, drop_rate, attn_drop_rate, drop_path_rate, head_drop_rate, norm_layer, init_values, use_learnable_pos_emb, init_scale, all_frames, tubelet_size, use_mean_pooling, with_cp, cos_attn)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mParameter(\n\u001b[1;32m    366\u001b[0m         torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m1\u001b[39m, num_patches, embed_dim))\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;66;03m# sine-cosine positional embeddings is on the way\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_embed \u001b[38;5;241m=\u001b[39m \u001b[43mget_sinusoid_encoding_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_patches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_drop \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39mdrop_rate)\n\u001b[1;32m    374\u001b[0m dpr \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, drop_path_rate, depth)\n\u001b[1;32m    375\u001b[0m        ]  \u001b[38;5;66;03m# stochastic depth decay rule\u001b[39;00m\n",
      "File \u001b[0;32m~/level2-3-cv-finalproject-cv-06/datapreprocess/models/modeling_finetune.py:313\u001b[0m, in \u001b[0;36mget_sinusoid_encoding_table\u001b[0;34m(n_position, d_hid)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_position_angle_vec\u001b[39m(position):\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    308\u001b[0m         position \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (hid_j \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m d_hid)\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m hid_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_hid)\n\u001b[1;32m    310\u001b[0m     ]\n\u001b[1;32m    312\u001b[0m sinusoid_table \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m--> 313\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mget_position_angle_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_i\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpos_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_position\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    314\u001b[0m sinusoid_table[:, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msin(sinusoid_table[:, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# dim 2i\u001b[39;00m\n\u001b[1;32m    315\u001b[0m sinusoid_table[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(sinusoid_table[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# dim 2i+1\u001b[39;00m\n",
      "File \u001b[0;32m~/level2-3-cv-finalproject-cv-06/datapreprocess/models/modeling_finetune.py:313\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_position_angle_vec\u001b[39m(position):\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m    308\u001b[0m         position \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mpower(\u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m (hid_j \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m d_hid)\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m hid_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_hid)\n\u001b[1;32m    310\u001b[0m     ]\n\u001b[1;32m    312\u001b[0m sinusoid_table \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[0;32m--> 313\u001b[0m     [\u001b[43mget_position_angle_vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m pos_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_position)])\n\u001b[1;32m    314\u001b[0m sinusoid_table[:, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msin(sinusoid_table[:, \u001b[38;5;241m0\u001b[39m::\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# dim 2i\u001b[39;00m\n\u001b[1;32m    315\u001b[0m sinusoid_table[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcos(sinusoid_table[:, \u001b[38;5;241m1\u001b[39m::\u001b[38;5;241m2\u001b[39m])  \u001b[38;5;66;03m# dim 2i+1\u001b[39;00m\n",
      "File \u001b[0;32m~/level2-3-cv-finalproject-cv-06/datapreprocess/models/modeling_finetune.py:307\u001b[0m, in \u001b[0;36mget_sinusoid_encoding_table.<locals>.get_position_angle_vec\u001b[0;34m(position)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_position_angle_vec\u001b[39m(position):\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhid_j\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md_hid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhid_j\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43md_hid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/level2-3-cv-finalproject-cv-06/datapreprocess/models/modeling_finetune.py:308\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_position_angle_vec\u001b[39m(position):\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m--> 308\u001b[0m         position \u001b[38;5;241m/\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mhid_j\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43md_hid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m hid_j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(d_hid)\n\u001b[1;32m    310\u001b[0m     ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "segments_num = 1\n",
    "# 모델에 들어갈 frame수는 16 * segments_num\n",
    "\n",
    "model = create_model(\n",
    "    # \"vit_small_patch16_224\",\n",
    "    \"vit_base_patch16_224\",\n",
    "    img_size=224,\n",
    "    pretrained=False,\n",
    "    num_classes=710,\n",
    "    all_frames=16 * segments_num,\n",
    "    # tubelet_size=args.tubelet_size,\n",
    "    # drop_rate=args.drop,\n",
    "    # drop_path_rate=args.drop_path,\n",
    "    # attn_drop_rate=args.attn_drop_rate,\n",
    "    # head_drop_rate=args.head_drop_rate,\n",
    "    # drop_block_rate=None,\n",
    "    # use_mean_pooling=args.use_mean_pooling,\n",
    "    # init_scale=args.init_scale,\n",
    "    # with_cp=args.with_checkpoint,\n",
    ")\n",
    "\n",
    "# load_dict = torch.load(\n",
    "#     \"/data/ephemeral/home/level2-3-cv-finalproject-cv-06/datapreprocess/vit_s_k710_dl_from_giant.pth\"\n",
    "# )\n",
    "load_dict = torch.load(\n",
    "    \"/data/ephemeral/home/level2-3-cv-finalproject-cv-06/datapreprocess/vit_b_k710_dl_from_giant.pth\"\n",
    ")\n",
    "# backbone pth 경로\n",
    "\n",
    "model.load_state_dict(load_dict[\"module\"])\n",
    "\n",
    "model.to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "tf = A.Resize(224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_3_14_65_BU_DYA_07-19_12-30-50_d_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYA_07-19_12-30-50_d_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:02\n",
      "C_3_14_65_BU_DYA_07-19_12-30-50_e_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYA_07-19_12-30-50_e_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_65_BU_DYA_07-19_12-30-50_f_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYA_07-19_12-30-50_f_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CA_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CA_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CB_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CB_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CC_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CC_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CD_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CD_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CE_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CE_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CF_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_65_BU_DYB_10-13_12-03-56_CF_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_a_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_a_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_b_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_b_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_c_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_c_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_d_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_d_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_e_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_e_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_f_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYA_07-19_11-46-00_f_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CA_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CA_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CB_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CB_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CC_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CC_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CD_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CD_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CE_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CE_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CF_DF2_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_66_BU_DYB_10-13_12-06-02_CF_DF2_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_a_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_a_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_b_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_b_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_c_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_c_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_d_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_d_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_e_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_e_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_f_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYA_07-19_11-54-57_f_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CA_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CA_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CB_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CB_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CC_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CC_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CD_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CD_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CE_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CE_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CF_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_67_BU_DYB_10-13_10-14-49_CF_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_a_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_a_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_b_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_b_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_c_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_c_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_d_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_d_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_e_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_e_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_f_DF6_F4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYA_07-19_12-04-44_f_DF6_F4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CA_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CA_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CB_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CB_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CC_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CC_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CD_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CD_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CE_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CE_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CF_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_68_BU_DYB_10-13_10-17-17_CF_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_a_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_a_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_b_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_b_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_c_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_c_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_d_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_d_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_e_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_e_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_f_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYA_07-20_14-59-57_f_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CA_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CA_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CB_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CB_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CC_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CC_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CD_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CD_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CE_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CE_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CF_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_69_BU_DYB_10-13_10-19-42_CF_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_a_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_a_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_b_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_b_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_c_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_c_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_d_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_d_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_e_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_e_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_f_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYA_07-20_15-01-52_f_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CA_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CA_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CB_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CB_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CC_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CC_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CD_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CD_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CE_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CE_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CF_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_70_BU_DYB_10-13_10-21-44_CF_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYA_07-20_15-04-31_a_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYA_07-20_15-04-31_a_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYA_07-20_15-04-31_b_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYA_07-20_15-04-31_b_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYA_07-20_15-04-31_c_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYA_07-20_15-04-31_c_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CA_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CA_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CB_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CB_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CC_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CC_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CD_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CD_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CE_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CE_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CF_DF2_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_71_BU_DYB_10-13_10-45-53_CF_DF2_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_72_BU_DYA_07-20_15-07-07_a_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_72_BU_DYA_07-20_15-07-07_a_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_72_BU_DYA_07-20_15-07-07_b_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_72_BU_DYA_07-20_15-07-07_b_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n",
      "C_3_14_72_BU_DYA_07-20_15-07-07_c_DF6_M4.mp4 feature extracting starts\n",
      "==>> file_outputs.shape: (12, 710)\n",
      "C_3_14_72_BU_DYA_07-20_15-07-07_c_DF6_M4.mp4 feature extracting ended. Elapsed time: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# Loop through the video frames\n",
    "for file_name in file_list:\n",
    "    path = root + file_name\n",
    "\n",
    "    time_start = datetime.now()\n",
    "\n",
    "    print(f\"{file_name} feature extracting starts\")\n",
    "\n",
    "    cap = cv2.VideoCapture(path)\n",
    "\n",
    "    # 710차원 feature array 저장할 list\n",
    "    np_list = []\n",
    "\n",
    "    # 16 * segments_num 프레임씩 저장할 list\n",
    "    frames = []\n",
    "    frame_count = 0\n",
    "\n",
    "    # input tensor 저장할 list\n",
    "    input_list = []\n",
    "    input_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "        # frame.shape = (height, width, 3)\n",
    "\n",
    "        frame_count += 1  # Increment frame count\n",
    "\n",
    "        if success:\n",
    "            frame = tf(image=frame)[\"image\"]\n",
    "            # frame.shape = (224, 224, 3)\n",
    "\n",
    "            frame = np.expand_dims(frame, axis=0)\n",
    "            # frame.shape = (1, 224, 224, 3)\n",
    "            frames.append(frame.copy())\n",
    "\n",
    "            if frame_count == 16 * segments_num:\n",
    "                assert len(frames) == 16 * segments_num\n",
    "                frames = np.concatenate(frames)\n",
    "                # in_frames.shape = (16 * segments_num, 224, 224, 3)\n",
    "                in_frames = frames.transpose(3, 0, 1, 2)\n",
    "                # # in_frames.shape = (RGB 3, frame T=16 * segments_num, H=224, W=224)\n",
    "                in_frames = np.expand_dims(in_frames, axis=0)\n",
    "                # in_frames.shape = (1, 3, 16 * segments_num, 224, 224)\n",
    "                in_frames = torch.from_numpy(in_frames).float()\n",
    "                # in_frames.shape == torch.Size([1, 3, 16 * segments_num, 224, 224])\n",
    "\n",
    "                input_list.append(in_frames.detach().clone())\n",
    "\n",
    "                frame_count = 0\n",
    "                frames = []\n",
    "\n",
    "                input_count += 1\n",
    "\n",
    "                if input_count == batch_size:\n",
    "                    # input_batch.shape == torch.Size([batch_size, 3, 16 * segments_num, 224, 224])\n",
    "                    input_batch = torch.cat(input_list, dim=0).to(\"cuda\")\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        output = model(input_batch)\n",
    "                        # output.shape == torch.Size([batch_size, 710])\n",
    "\n",
    "                    np_list.append(output.cpu().numpy())\n",
    "\n",
    "                    input_count = 0\n",
    "                    input_list = []\n",
    "        else:\n",
    "            # 남은 프레임, input_list가 지정 개수에서 모자를 때 예외 처리\n",
    "            if frame_count != 0:\n",
    "                len_frames_left = 16 * segments_num - len(frames)\n",
    "                # len_input_list_left = batch_size - len(input_list)\n",
    "                for i in range(len_frames_left):\n",
    "                    frames.append(frames[-1].copy())\n",
    "\n",
    "                assert len(frames) == 16 * segments_num\n",
    "\n",
    "                frames = np.concatenate(frames)\n",
    "                # in_frames.shape = (16 * segments_num, 224, 224, 3)\n",
    "                in_frames = frames.transpose(3, 0, 1, 2)\n",
    "                # # in_frames.shape = (RGB 3, frame T=16 * segments_num, H=224, W=224)\n",
    "                in_frames = np.expand_dims(in_frames, axis=0)\n",
    "                # in_frames.shape = (1, 3, 16 * segments_num, 224, 224)\n",
    "                in_frames = torch.from_numpy(in_frames).float()\n",
    "                # in_frames.shape == torch.Size([1, 3, 16 * segments_num, 224, 224])\n",
    "\n",
    "                input_list.append(in_frames.detach().clone())\n",
    "\n",
    "                # assert len(input_list) == batch_size\n",
    "\n",
    "                # input_batch.shape == torch.Size([batch_size, 3, 16 * segments_num, 224, 224])\n",
    "                input_batch = torch.cat(input_list, dim=0).to(\"cuda\")\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    output = model(input_batch)\n",
    "                    # output.shape == torch.Size([len(input_list), 710])\n",
    "\n",
    "                np_list.append(output.cpu().numpy())\n",
    "\n",
    "                frame_count = 0\n",
    "                frames = []\n",
    "                input_count = 0\n",
    "                input_list = []\n",
    "\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    file_outputs = np.concatenate(np_list)\n",
    "    print(f\"==>> file_outputs.shape: {file_outputs.shape}\")\n",
    "\n",
    "    np.save((npy_root + folder_name + \"_base/\" + file_name), file_outputs)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    time_end = datetime.now()\n",
    "    total_time = time_end - time_start\n",
    "    total_time = str(total_time).split(\".\")[0]\n",
    "\n",
    "    print(f\"{file_name} feature extracting ended. Elapsed time: {total_time}\")\n",
    "\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
